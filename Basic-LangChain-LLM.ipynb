{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9fddb1",
   "metadata": {},
   "source": [
    "# Lab Statement: Introduction to Creating RAGs (Retrieval-Augmented Generators) with OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd58b3d",
   "metadata": {},
   "source": [
    "## Name: David Santiago Castro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37d1dd8",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ac7ee",
   "metadata": {},
   "source": [
    "To begin with, we need to have LangChain installed and the environment set up to import the environment, have an OpenAI account, and have an API key in our environment. In this case, we use the GitHub Education license so that we don't have to pay for the API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb418dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.10)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.13 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openai) (1.2.14)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=2.20.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openai) (2.21.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai) (2.12.5)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai) (0.7.6)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai) (4.15.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai) (9.1.4)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai) (26.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai) (0.14.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai) (6.0.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.12.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2026.1.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=2.20.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=2.20.0->langchain-openai) (3.11)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=2.20.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=2.20.0->langchain-openai) (2026.1.4)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=2.20.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.13->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-openai) (3.11.7)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-openai) (3.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain-openai) (2.41.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain-openai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>4->openai<3.0.0,>=2.20.0->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-openai\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b2c7be",
   "metadata": {},
   "source": [
    "## Build a basic agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddd32e",
   "metadata": {},
   "source": [
    "We start by creating a simple agent that can answer questions and call tools. The agent will use gpt-4o as a language model, a basic weather function as a tool, and a simple prompt where we guide its behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3429682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='ec8f1010-2271-4fea-9acf-059cfe02ced7'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 56, 'total_tokens': 72, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_af7f7349a4', 'id': 'chatcmpl-DBwzvWBL4BhthclvJixBavFfJrk6n', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c83fa-a402-7192-9cbd-9864692b0623-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_IhaWEOWBGw7FYiOvGuvDlFR2', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 56, 'output_tokens': 16, 'total_tokens': 72, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='5edf37e6-8bc0-43c0-8946-72d7955a8705', tool_call_id='call_IhaWEOWBGw7FYiOvGuvDlFR2'), AIMessage(content=\"It's always sunny in San Francisco! ☀️\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 86, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_af7f7349a4', 'id': 'chatcmpl-DBwzwhS2EBYUKqxosRHITXkoUPF0A', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c83fa-aa14-7110-91b8-14c6828867ea-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 86, 'output_tokens': 12, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "load_dotenv()  \n",
    "github_token = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\", \n",
    "    api_key=github_token,\n",
    "    base_url=\"https://models.inference.ai.azure.com\"\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    "    )\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154ea98",
   "metadata": {},
   "source": [
    "In the basic agent section, we load our API key from the environment, create a simple weather tool, and connect both to a ChatOpenAI model so the agent can reason and call tools when needed. Then, we define a short system prompt to guide behavior and send a user message like asking for weather in SF. When invoked, the agent decides whether to use the tool, gets the tool result, and returns a final natural-language answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f8646",
   "metadata": {},
   "source": [
    "## Build a real-world agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f074c6",
   "metadata": {},
   "source": [
    "In the following message, we define the role and behavior of our agent. It is important to be specific and practical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef51899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d5cd4d",
   "metadata": {},
   "source": [
    "We define two tools for a weather agent: one tool returns a simple weather message for a given city, and the other tool gets the user’s location based on a runtime context. It also creates a small Contex` data class with a user_id field, so the agent can pass user information while running tools. In short, this setup allows the agent to either answer weather questions for a specific city or infer the city from the current user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "493c9dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21585f18",
   "metadata": {},
   "source": [
    "We configure a ChatOpenAI language model instance using gpt-4o, reads the API key from the environment variable GITHUB_TOKEN for safer credential handling, connects to the Azure inference endpoint through base_url, and sets temperature equals 0.5 so responses stay reasonably consistent while still allowing some creativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9515c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c110fe2",
   "metadata": {},
   "source": [
    "We define a simple structured output format responseFormat so the agent replies with a punny weather message and optional weather details, then creates an in memory checkpointer to keep conversation state across turns. After that, it builds an agent with the weather tools, the system prompt, and user context support, and configures a fixed thread ID so both calls belong to the same conversation. Finally, it invokes the agent twice and prints only the structured responses, showing how the agent keeps context while returning clean, predictable output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fa6d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    punny_response: str\n",
    "    weather_conditions: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5245a2",
   "metadata": {},
   "source": [
    "We set up a conversational weather agent with short-term memory so it can keep context between messages. First, it creates an in-memory checkpointer InMemorySaver to store the conversation state. Then it builds the agent using the existing model, system prompt, weather tools, and a context schema Context so the agent can use user-specific information. A fixed thread ID is defined in config to make both requests part of the same chat session. Finally, the agent is called twice, and only the structured output is printed, showing clear responses and continuity across turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "702993c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec62745",
   "metadata": {},
   "source": [
    "We build a weather assistant agent that uses the existing model, prompt, tools, and memory so it can keep context across messages. It sets a thread_id to keep both requests in the same conversation, then calls the agent first to ask for the weather outside, and calls it again to say thank yo. In both cases, it prints only the structured output, which makes the responses cleaner and consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ede24984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(punny_response='Looks like Florida is living up to its name with sunshine galore!', weather_conditions='Sunny')\n",
      "ResponseFormat(punny_response=\"You're very welcome! I'm always here to make your day a little brighter, rain or shine.\", weather_conditions=None)\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ccfd14",
   "metadata": {},
   "source": [
    "When it comes to building a real world agent, we move from a basic example to a more useful and robust solution: \n",
    "The agent not only responds, but also uses specific tools, maintains context between messages with memory, leverages user information through a context schema, and delivers structured outputs to be clear and predictable. \n",
    "Together, this demonstrates how to design an assistant that is closer to a real production case\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
